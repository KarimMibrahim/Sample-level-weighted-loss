{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import strftime, localtime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, cohen_kappa_score, hamming_loss\n",
    "\n",
    "# [TODO] edit the path to the tfslim directoy \"https://github.com/tensorflow/models/tree/master/research/slim\"\n",
    "SLIM_PATH = '/srv/workspace/research/mlml/models/research/slim'\n",
    "os.chdir(SLIM_PATH)\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from nets import inception\n",
    "from datasets import dataset_utils\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "# [TODO] edit the paths to match the machine's directories \n",
    "SOURCE_PATH = \"/srv/workspace/research/mlml/mlml_weightedLoss/\"\n",
    "# path to the formatted dataset\n",
    "IMAGES_PATH = \"/srv/workspace/research/mlml/datasets/mscoco/train_formatted_normalized_npz/\"\n",
    "TEST_IMAGES_PATH = IMAGES_PATH\n",
    "# path to the output direcorty\n",
    "OUTPUT_PATH =\"/srv/workspace/research/mlml/experiments_results_balanced/\"\n",
    "# path to the pretrained model (if not downloaded already, call the download_pretrained_model function below)\n",
    "PRETRAINED_MODEL_DIR = '/srv/workspace/research/mlml/pretrained_models/'\n",
    "\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "INPUT_IMAGE_MEAN = [0.485, 0.456, 0.406]\n",
    "INPUT_IMAGE_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "labels_set = pd.read_csv('/srv/workspace/research/mlml/mlml_weightedLoss/labels_balanced_4labels/missing_labels0.0/train1_0.0.csv')\n",
    "labels_set.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "\n",
    "LABELS_LIST = labels_set.columns\n",
    "NUM_CLASSES = len(LABELS_LIST)\n",
    "\n",
    "# Training paramaeters\n",
    "BATCH_SIZE = 32\n",
    "TRAINING_STEPS = int(len(labels_set)/BATCH_SIZE)\n",
    "NUM_EPOCHS = 20\n",
    "# compute the weights to balance between the ratio of positive and negative samples per label (not the confidence-based weights) \n",
    "Pos_balance_weights = np.round((1 / (np.sum(labels_set.values, axis = 0)/ len(labels_set))/2)).astype(np.float32)\n",
    "Pos_balance_weights = np.clip(Pos_balance_weights,1,10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "code_folding": [
     1,
     7,
     12,
     18,
     24,
     41,
     48,
     51,
     77,
     96,
     106,
     118,
     125,
     136,
     193,
     218,
     335,
     366,
     389,
     407,
     428
    ]
   },
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "\n",
    "def download_pretrained_model():\n",
    "    url = \"http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz\"\n",
    "    if not tf.gfile.Exists(PRETRAINED_MODEL_DIR):\n",
    "        tf.gfile.MakeDirs(PRETRAINED_MODEL_DIR)\n",
    "    dataset_utils.download_and_uncompress_tarball(url, PRETRAINED_MODEL_DIR)\n",
    "\n",
    "# functions for defining the model\n",
    "def get_weights(shape):\n",
    "    w = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "    return w\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    b = tf.Variable(initial)\n",
    "    return b\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = get_weights([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b\n",
    "\n",
    "def dataset_from_csv(csv_path, **kwargs):\n",
    "    \"\"\"\n",
    "        Load dataset from a csv file.\n",
    "        kwargs are forwarded to the pandas.read_csv function.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, **kwargs)\n",
    "\n",
    "    dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices(\n",
    "            {\n",
    "                key:df[key].values\n",
    "                for key in df\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "def set_tensor_shape(tensor, tensor_shape):\n",
    "        \"\"\"\n",
    "            set shape for a tensor (not in place, as opposed to tf.set_shape)\n",
    "        \"\"\"\n",
    "        tensor.set_shape(tensor_shape)\n",
    "        return tensor\n",
    "\n",
    "def mscoco_labels_idx_to_names(labels,labelnames = LABELS_LIST):\n",
    "    return labelnames[np.where(labels == 1)]\n",
    "\n",
    "# Dataset piplines [load images]\n",
    "def load_image_npz(*args):\n",
    "    \"\"\"\n",
    "        loads image with error tracking.\n",
    "        args : image ID, path to dataset\n",
    "        return:\n",
    "            Features: numpy ndarray, computed features (if no error occured, otherwise: 0)\n",
    "            Error: boolean, False if no error, True if an error was raised during features computation.\n",
    "    \"\"\"\n",
    "    path = IMAGES_PATH\n",
    "    image_id, dummy_path = args\n",
    "    try:\n",
    "        image = np.load(os.path.join(path, str(image_id) + '.npz'))['image']\n",
    "        return image, False\n",
    "    except Exception as err:\n",
    "        print(\"\\n Error while computing features for \" + str(image_id) + '\\n')\n",
    "        return np.float32(0.0), True\n",
    "\n",
    "def load_imge_tf(sample, identifier_key=\"Unnamed: 0\",\n",
    "                 path=\"/srv/workspace/research/mlml/datasets/mscoco/train_formatted_npz/\", device=\"/cpu:0\",\n",
    "                 features_key=\"features\"):\n",
    "    \"\"\"\n",
    "        wrap load_images into a tensorflow function.\n",
    "    \"\"\"\n",
    "    with tf.device(device):\n",
    "        input_args = [sample[identifier_key], tf.constant(path)]\n",
    "        res = tf.py_func(load_image_npz,\n",
    "                         input_args,\n",
    "                         (tf.float32, tf.bool),\n",
    "                         stateful=False),\n",
    "        image, error = res[0]\n",
    "        image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "        res = dict(list(sample.items()) + [(features_key, image), (\"error\", error)])\n",
    "        return res\n",
    "\n",
    "    \n",
    "# Dataset pipelines [load weights]\n",
    "def get_weights_py(image_id):\n",
    "    weights_negative = global_weights_negative[global_weights_negative.iloc[:,0] == image_id]\n",
    "    samples_weights_negative = weights_negative.iloc[:, 1:].values.flatten()\n",
    "    samples_weights_negative = samples_weights_negative.astype(np.float32)\n",
    "    return samples_weights_negative\n",
    "\n",
    "def tf_get_weights_py(sample,device = \"/cpu:0\"):\n",
    "    with tf.device(device):\n",
    "        input_args = [sample[\"Unnamed: 0\"]]\n",
    "        negative_weights = tf.py_func(get_weights_py,\n",
    "            input_args,\n",
    "            [tf.float32],\n",
    "            stateful=False)\n",
    "        res = dict(list(sample.items()) + [(\"negative_weights\", negative_weights)])\n",
    "        return res\n",
    "    \n",
    "\n",
    "# Dataset pipelines [load labels]\n",
    "def get_labels_py(image_id):\n",
    "    labels = global_labels[global_labels.iloc[:,0] == image_id]\n",
    "    labels = labels.iloc[:, 1:].values.flatten()\n",
    "    labels = labels.astype(np.float32)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def tf_get_labels_py(sample, device=\"/cpu:0\"):\n",
    "    with tf.device(device):\n",
    "        input_args = [sample[\"Unnamed: 0\"]]\n",
    "        labels = tf.py_func(get_labels_py,\n",
    "                            input_args,\n",
    "                            [tf.float32],\n",
    "                            stateful=False)\n",
    "        res = dict(list(sample.items()) + [(\"binary_label\", labels)])\n",
    "        return res\n",
    "\n",
    "\n",
    "def get_dataset(input_csv, input_shape=INPUT_SHAPE, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                infinite_generator=True, random_crop=False,\n",
    "                num_parallel_calls=32):\n",
    "    # build dataset from csv file\n",
    "    dataset = dataset_from_csv(input_csv)\n",
    "    # Shuffle data\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=100, seed=0, reshuffle_each_iteration=True)\n",
    "\n",
    "    # load image\n",
    "    dataset = dataset.map(lambda sample: load_imge_tf(sample), num_parallel_calls=1)\n",
    "\n",
    "    # filter out errors\n",
    "    dataset = dataset.filter(lambda sample: tf.logical_not(sample[\"error\"]))\n",
    "\n",
    "    # set features shape\n",
    "    dataset = dataset.map(lambda sample: dict(sample,\n",
    "                                              features=set_tensor_shape(sample[\"features\"], input_shape)))\n",
    "\n",
    "    dataset = dataset.map(lambda sample: tf_get_labels_py(sample), num_parallel_calls=1)\n",
    "\n",
    "    # set output shape\n",
    "    dataset = dataset.map(lambda sample: dict(sample, binary_label=set_tensor_shape(\n",
    "        sample[\"binary_label\"], (NUM_CLASSES))))\n",
    "    \n",
    "    # load weights\n",
    "    dataset = dataset.map(lambda sample: tf_get_weights_py(sample), num_parallel_calls=1)\n",
    "    \n",
    "    dataset = dataset.map(lambda sample: dict(sample, negative_weights=set_tensor_shape(\n",
    "    sample[\"negative_weights\"], (NUM_CLASSES))))\n",
    "    \n",
    "    if infinite_generator:\n",
    "        # Repeat indefinitly\n",
    "        dataset = dataset.repeat(count=-1)\n",
    "\n",
    "    # Make batch\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Select only features and annotation\n",
    "    dataset = dataset.map(lambda sample: (sample[\"features\"], sample[\"binary_label\"],\n",
    "                                          sample[\"negative_weights\"]))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def create_analysis_report(model_output, groundtruth, output_path, LABELS_LIST, validation_output=None,\n",
    "                           validation_groundtruth=None):\n",
    "    \"\"\"\n",
    "    Create a report of all the different evaluation metrics, including optimizing the threshold with the validation set\n",
    "    if it is passed in the parameters\n",
    "    \"\"\"\n",
    "    # Round the probabilities at 0.5\n",
    "    model_output_rounded = np.round(model_output)\n",
    "    model_output_rounded = np.clip(model_output_rounded, 0, 1)\n",
    "    # Create a dataframe where we keep all the evaluations, starting by prediction accuracy\n",
    "    accuracies_perclass = sum(model_output_rounded == groundtruth) / len(groundtruth)\n",
    "    results_df = pd.DataFrame(columns=LABELS_LIST)\n",
    "    results_df.index.astype(str, copy=False)\n",
    "    percentage_of_positives_perclass = sum(groundtruth) / len(groundtruth)\n",
    "    results_df.loc[0] = percentage_of_positives_perclass\n",
    "    results_df.loc[1] = accuracies_perclass\n",
    "    results_df.index = ['Ratio of positive samples', 'Model accuracy']\n",
    "\n",
    "    # plot the accuracies per class\n",
    "    results_df.T.plot.bar(figsize=(22, 12), fontsize=18)\n",
    "    plt.title('Model accuracy vs the ratio of positive samples per class')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(os.path.join(output_path, \"accuracies_vs_positiveRate.pdf\"), format=\"pdf\")\n",
    "    plt.savefig(os.path.join(output_path, \"accuracies_vs_positiveRate.png\"))\n",
    "\n",
    "    # Getting the true positive rate perclass\n",
    "    true_positives_ratio_perclass = sum((model_output_rounded == groundtruth) * (groundtruth == 1)) / sum(groundtruth)\n",
    "    results_df.loc[2] = true_positives_ratio_perclass\n",
    "    # Get true negative ratio\n",
    "    true_negative_ratio_perclass = sum((model_output_rounded == groundtruth)\n",
    "                                       * (groundtruth == 0)) / (len(groundtruth) - sum(groundtruth))\n",
    "    results_df.loc[3] = true_negative_ratio_perclass\n",
    "    # compute additional metrics (AUC,f1,recall,precision)\n",
    "    auc_roc_per_label = roc_auc_score(groundtruth, model_output, average=None)\n",
    "    precision_perlabel = precision_score(groundtruth, model_output_rounded, average=None)\n",
    "    recall_perlabel = recall_score(groundtruth, model_output_rounded, average=None)\n",
    "    f1_perlabel = f1_score(groundtruth, model_output_rounded, average=None)\n",
    "    kappa_perlabel = [cohen_kappa_score(groundtruth[:, x], model_output_rounded[:, x]) for x in range(len(LABELS_LIST))]\n",
    "    results_df = results_df.append(\n",
    "        pd.DataFrame([auc_roc_per_label,recall_perlabel, precision_perlabel, f1_perlabel, kappa_perlabel], columns=LABELS_LIST))\n",
    "    results_df.index = ['Ratio of positive samples', 'Model accuracy', 'True positives ratio',\n",
    "                        'True negatives ratio', \"AUC\", \"Recall\", \"Precision\", \"f1-score\", \"Kappa score\"]\n",
    "\n",
    "\n",
    "    # Adjusting threshold based on validation set\n",
    "    if (validation_groundtruth is not None and validation_output is not None):\n",
    "        np.savetxt(os.path.join(output_path, 'validation_predictions.out'), validation_output, delimiter=',')\n",
    "        np.savetxt(os.path.join(output_path, 'valid_ground_truth_classes.txt'), validation_groundtruth, delimiter=',')\n",
    "        thresholds = np.arange(0, 1, 0.01)\n",
    "        f1_array = np.zeros((len(LABELS_LIST), len(thresholds)))\n",
    "        for idx, label in enumerate(LABELS_LIST):\n",
    "            f1_array[idx, :] = [\n",
    "                f1_score(validation_groundtruth[:, idx], np.clip(np.round(validation_output[:, idx] - threshold + 0.5), 0, 1))\n",
    "                for threshold in thresholds]\n",
    "        threshold_arg = np.argmax(f1_array, axis=1)\n",
    "        threshold_per_class = thresholds[threshold_arg]\n",
    "\n",
    "        # plot the f1 score across thresholds\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        for idx, x in enumerate(LABELS_LIST):\n",
    "            plt.plot(thresholds, f1_array[idx, :], linewidth=5)\n",
    "        plt.legend(LABELS_LIST, loc='best')\n",
    "        plt.title(\"F1 Score vs different prediction threshold values for each class\")\n",
    "        plt.savefig(os.path.join(output_path, \"f1_score_vs_thresholds.pdf\"), format=\"pdf\")\n",
    "        plt.savefig(os.path.join(output_path, \"f1_score_vs_thresholds.png\"))\n",
    "\n",
    "        # Applying thresholds optimized per class\n",
    "        model_output_rounded = np.zeros_like(model_output)\n",
    "        for idx, label in enumerate(LABELS_LIST):\n",
    "            model_output_rounded[:, idx] = np.clip(np.round(model_output[:, idx] - threshold_per_class[idx] + 0.5), 0, 1)\n",
    "\n",
    "        accuracies_perclass = sum(model_output_rounded == groundtruth) / len(groundtruth)\n",
    "        # Getting the true positive rate perclass\n",
    "        true_positives_ratio_perclass = sum((model_output_rounded == groundtruth) * (groundtruth == 1)) / sum(\n",
    "            groundtruth)\n",
    "        # Get true negative ratio\n",
    "        true_negative_ratio_perclass = sum((model_output_rounded == groundtruth)\n",
    "                                           * (groundtruth == 0)) / (len(groundtruth) - sum(groundtruth))\n",
    "        results_df = results_df.append(\n",
    "            pd.DataFrame([accuracies_perclass, true_positives_ratio_perclass,\n",
    "                          true_negative_ratio_perclass], columns=LABELS_LIST))\n",
    "        # compute additional metrics (AUC,f1,recall,precision)\n",
    "        auc_roc_per_label = roc_auc_score(groundtruth, model_output, average=None)\n",
    "        precision_perlabel = precision_score(groundtruth, model_output_rounded, average=None)\n",
    "        recall_perlabel = recall_score(groundtruth, model_output_rounded, average=None)\n",
    "        f1_perlabel = f1_score(groundtruth, model_output_rounded, average=None)\n",
    "        kappa_perlabel = [cohen_kappa_score(groundtruth[:, x], model_output_rounded[:, x]) for x in\n",
    "                          range(len(LABELS_LIST))]\n",
    "        results_df = results_df.append(\n",
    "            pd.DataFrame([auc_roc_per_label,recall_perlabel, precision_perlabel, f1_perlabel,kappa_perlabel],\n",
    "                         columns=LABELS_LIST))\n",
    "        results_df.index = ['Ratio of positive samples', 'Model accuracy', 'True positives ratio',\n",
    "                            'True negatives ratio', \"AUC\", \"Precision\", \"Recall\", \"f1-score\",  \"Kappa score\",\n",
    "                            'Optimized model accuracy', 'Optimized true positives ratio',\n",
    "                            'Optimized true negatives ratio', \"Optimized AUC\",\n",
    "                            \"Optimized precision\", \"Optimized recall\", \"Optimized f1-score\",  \"Optimized Kappa score\"]\n",
    "\n",
    "    results_df['average'] = results_df.mean(numeric_only=True, axis=1)\n",
    "    results_df.T.to_csv(os.path.join(output_path, \"results_report.csv\"), float_format=\"%.2f\")\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def evaluate_model(test_pred_prob, test_classes, saving_path, evaluation_file_path):\n",
    "    \"\"\"\n",
    "    Evaluates a given model using accuracy, area under curve and hamming loss\n",
    "    :param model: model to be evaluated\n",
    "    :param spectrograms: the test set spectrograms as an np.array\n",
    "    :param test_classes: the ground truth labels\n",
    "    :return: accuracy, auc_roc, hamming_error\n",
    "    \"\"\"\n",
    "    test_pred = np.round(test_pred_prob)\n",
    "    # Accuracy\n",
    "    accuracy = 100 * accuracy_score(test_classes, test_pred)\n",
    "    print(\"Exact match accuracy is: \" + str(accuracy) + \"%\")\n",
    "    # Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
    "    auc_roc = roc_auc_score(test_classes, test_pred_prob)\n",
    "    print(\"Macro Area Under the Curve (AUC) is: \" + str(auc_roc))\n",
    "    auc_roc_micro = roc_auc_score(test_classes, test_pred_prob, average=\"micro\")\n",
    "    print(\"Micro Area Under the Curve (AUC) is: \" + str(auc_roc_micro))\n",
    "    auc_roc_weighted = roc_auc_score(test_classes, test_pred_prob, average=\"weighted\")\n",
    "    print(\"Weighted Area Under the Curve (AUC) is: \" + str(auc_roc_weighted))\n",
    "    # Hamming loss is the fraction of labels that are incorrectly predicted.\n",
    "    hamming_error = hamming_loss(test_classes, test_pred)\n",
    "    print(\"Hamming Loss (ratio of incorrect tags) is: \" + str(hamming_error))\n",
    "    with open(evaluation_file_path, \"w\") as f:\n",
    "        f.write(\"Exact match accuracy is: \" + str(accuracy) + \"%\\n\" + \"Area Under the Curve (AUC) is: \" + str(auc_roc)\n",
    "                + \"\\nMicro AUC is:\" + str(auc_roc_micro) + \"\\nWeighted AUC is:\" + str(auc_roc_weighted)\n",
    "                + \"\\nHamming Loss (ratio of incorrect tags) is: \" + str(hamming_error))\n",
    "    print(\"saving prediction to disk\")\n",
    "    np.savetxt(os.path.join(saving_path, 'predictions.out'), test_pred_prob, delimiter=',')\n",
    "    np.savetxt(os.path.join(saving_path, 'test_ground_truth_classes.txt'), test_classes, delimiter=',')\n",
    "    return accuracy, auc_roc, hamming_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine-tune pretrained model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: PosLimited_original_CE_balanced_ratio0.0split_1\n",
      "\n",
      "\n",
      "\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results_balanced/PosLimited_original_CE_balanced_ratio0.0split_1/19-12_11-24\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_resnet_v2_2016_08_30.ckpt\n",
      "Epoch #1 Loss: 0.7099 accuracy: 0.8937\n",
      "Epoch #2 Loss: 0.6609 accuracy: 0.9385\n",
      "Epoch #3 Loss: 0.6464 accuracy: 0.9391\n",
      "Epoch #4 Loss: 0.6250 accuracy: 0.9401\n",
      "Epoch #5 Loss: 0.5973 accuracy: 0.9382\n",
      "Epoch #6 Loss: 0.5676 accuracy: 0.9309\n",
      "Epoch #7 Loss: 0.5424 accuracy: 0.9214\n",
      "Epoch #8 Loss: 0.5239 accuracy: 0.9139\n",
      "Epoch #9 Loss: 0.5108 accuracy: 0.9094\n",
      "Epoch #10 Loss: 0.5005 accuracy: 0.9071\n",
      "Epoch #11 Loss: 0.4918 accuracy: 0.9056\n",
      "Epoch #12 Loss: 0.4845 accuracy: 0.9052\n",
      "Epoch #13 Loss: 0.4782 accuracy: 0.9050\n",
      "Epoch #14 Loss: 0.4724 accuracy: 0.9051\n",
      "Epoch #15 Loss: 0.4671 accuracy: 0.9052\n",
      "Epoch #16 Loss: 0.4626 accuracy: 0.9055\n",
      "Epoch #17 Loss: 0.4577 accuracy: 0.9059\n",
      "Epoch #18 Loss: 0.4539 accuracy: 0.9059\n",
      "Epoch #19 Loss: 0.4504 accuracy: 0.9061\n",
      "Epoch #20 Loss: 0.4455 accuracy: 0.9070\n",
      "Exact match accuracy is: 0.08412450426631415%\n",
      "Macro Area Under the Curve (AUC) is: 0.8747805212061313\n",
      "Micro Area Under the Curve (AUC) is: 0.9135003140455494\n",
      "Weighted Area Under the Curve (AUC) is: 0.8520347203175356\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.10158334334815527\n",
      "saving prediction to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: PosLimited_original_CE_balanced_ratio0.2split_1\n",
      "\n",
      "\n",
      "\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results_balanced/PosLimited_original_CE_balanced_ratio0.2split_1/19-12_12-17\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_resnet_v2_2016_08_30.ckpt\n",
      "Epoch #1 Loss: 0.6159 accuracy: 0.9074\n",
      "Epoch #2 Loss: 0.5633 accuracy: 0.9517\n",
      "Epoch #3 Loss: 0.5555 accuracy: 0.9520\n",
      "Epoch #4 Loss: 0.5452 accuracy: 0.9523\n",
      "Epoch #5 Loss: 0.5312 accuracy: 0.9528\n",
      "Epoch #6 Loss: 0.5141 accuracy: 0.9530\n",
      "Epoch #7 Loss: 0.4952 accuracy: 0.9515\n",
      "Epoch #8 Loss: 0.4781 accuracy: 0.9471\n",
      "Epoch #9 Loss: 0.4633 accuracy: 0.9416\n",
      "Epoch #10 Loss: 0.4526 accuracy: 0.9365\n",
      "Epoch #11 Loss: 0.4434 accuracy: 0.9326\n",
      "Epoch #12 Loss: 0.4361 accuracy: 0.9300\n",
      "Epoch #13 Loss: 0.4305 accuracy: 0.9283\n",
      "Epoch #14 Loss: 0.4251 accuracy: 0.9276\n",
      "Epoch #15 Loss: 0.4203 accuracy: 0.9268\n",
      "Epoch #16 Loss: 0.4167 accuracy: 0.9265\n",
      "Epoch #17 Loss: 0.4125 accuracy: 0.9264\n",
      "Epoch #18 Loss: 0.4088 accuracy: 0.9264\n",
      "Epoch #19 Loss: 0.4064 accuracy: 0.9263\n",
      "Epoch #20 Loss: 0.4021 accuracy: 0.9265\n",
      "Exact match accuracy is: 0.21632015382766495%\n",
      "Macro Area Under the Curve (AUC) is: 0.8669820360408235\n",
      "Micro Area Under the Curve (AUC) is: 0.9059138580415049\n",
      "Weighted Area Under the Curve (AUC) is: 0.8424155143315035\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.08211302728037495\n",
      "saving prediction to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: PosLimited_original_CE_balanced_ratio0.5split_1\n",
      "\n",
      "\n",
      "\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results_balanced/PosLimited_original_CE_balanced_ratio0.5split_1/19-12_13-28\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_resnet_v2_2016_08_30.ckpt\n",
      "Epoch #1 Loss: 0.5052 accuracy: 0.9299\n",
      "Epoch #2 Loss: 0.4521 accuracy: 0.9658\n",
      "Epoch #3 Loss: 0.4487 accuracy: 0.9658\n",
      "Epoch #4 Loss: 0.4445 accuracy: 0.9658\n",
      "Epoch #5 Loss: 0.4385 accuracy: 0.9659\n",
      "Epoch #6 Loss: 0.4312 accuracy: 0.9658\n",
      "Epoch #7 Loss: 0.4218 accuracy: 0.9658\n",
      "Epoch #8 Loss: 0.4112 accuracy: 0.9658\n",
      "Epoch #9 Loss: 0.3999 accuracy: 0.9654\n",
      "Epoch #10 Loss: 0.3892 accuracy: 0.9644\n",
      "Epoch #11 Loss: 0.3795 accuracy: 0.9626\n",
      "Epoch #12 Loss: 0.3718 accuracy: 0.9604\n",
      "Epoch #13 Loss: 0.3659 accuracy: 0.9580\n",
      "Epoch #14 Loss: 0.3608 accuracy: 0.9562\n",
      "Epoch #15 Loss: 0.3565 accuracy: 0.9547\n",
      "Epoch #16 Loss: 0.3528 accuracy: 0.9534\n",
      "Epoch #17 Loss: 0.3495 accuracy: 0.9525\n",
      "Epoch #18 Loss: 0.3468 accuracy: 0.9518\n",
      "Epoch #19 Loss: 0.3442 accuracy: 0.9513\n",
      "Epoch #20 Loss: 0.3409 accuracy: 0.9510\n",
      "Exact match accuracy is: 0.38456916236029326%\n",
      "Macro Area Under the Curve (AUC) is: 0.8534090394325158\n",
      "Micro Area Under the Curve (AUC) is: 0.9005939933427649\n",
      "Weighted Area Under the Curve (AUC) is: 0.8375446055310125\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.06744081240235549\n",
      "saving prediction to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: PosLimited_original_CE_balanced_ratio0.8split_1\n",
      "\n",
      "\n",
      "\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results_balanced/PosLimited_original_CE_balanced_ratio0.8split_1/19-12_14-39\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_resnet_v2_2016_08_30.ckpt\n",
      "Epoch #1 Loss: 0.3593 accuracy: 0.9415\n",
      "Epoch #2 Loss: 0.2809 accuracy: 0.9832\n",
      "Epoch #3 Loss: 0.2796 accuracy: 0.9833\n",
      "Epoch #4 Loss: 0.2788 accuracy: 0.9833\n",
      "Epoch #5 Loss: 0.2779 accuracy: 0.9833\n",
      "Epoch #6 Loss: 0.2771 accuracy: 0.9833\n",
      "Epoch #7 Loss: 0.2757 accuracy: 0.9833\n",
      "Epoch #8 Loss: 0.2744 accuracy: 0.9832\n",
      "Epoch #9 Loss: 0.2727 accuracy: 0.9833\n",
      "Epoch #10 Loss: 0.2708 accuracy: 0.9832\n",
      "Epoch #11 Loss: 0.2684 accuracy: 0.9833\n",
      "Epoch #12 Loss: 0.2658 accuracy: 0.9833\n",
      "Epoch #13 Loss: 0.2631 accuracy: 0.9832\n",
      "Epoch #14 Loss: 0.2599 accuracy: 0.9833\n",
      "Epoch #15 Loss: 0.2566 accuracy: 0.9832\n",
      "Epoch #16 Loss: 0.2531 accuracy: 0.9832\n",
      "Epoch #17 Loss: 0.2498 accuracy: 0.9832\n",
      "Epoch #18 Loss: 0.2467 accuracy: 0.9832\n",
      "Epoch #19 Loss: 0.2438 accuracy: 0.9831\n",
      "Epoch #20 Loss: 0.2408 accuracy: 0.9829\n",
      "Exact match accuracy is: 0.012017786323759164%\n",
      "Macro Area Under the Curve (AUC) is: 0.7946353822769011\n",
      "Micro Area Under the Curve (AUC) is: 0.8792964048447713\n",
      "Weighted Area Under the Curve (AUC) is: 0.8122949416112123\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.06551496214397308\n",
      "saving prediction to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: PosLimited_original_CE_balanced_ratio0.0split_2\n",
      "\n",
      "\n",
      "\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results_balanced/PosLimited_original_CE_balanced_ratio0.0split_2/19-12_15-52\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_resnet_v2_2016_08_30.ckpt\n",
      "Epoch #1 Loss: 0.7081 accuracy: 0.9021\n",
      "Epoch #2 Loss: 0.6619 accuracy: 0.9384\n",
      "Epoch #3 Loss: 0.6463 accuracy: 0.9388\n",
      "Epoch #4 Loss: 0.6249 accuracy: 0.9394\n",
      "Epoch #5 Loss: 0.5970 accuracy: 0.9367\n",
      "Epoch #6 Loss: 0.5668 accuracy: 0.9284\n",
      "Epoch #7 Loss: 0.5408 accuracy: 0.9186\n",
      "Epoch #8 Loss: 0.5224 accuracy: 0.9114\n",
      "Epoch #9 Loss: 0.5089 accuracy: 0.9071\n",
      "Epoch #10 Loss: 0.4991 accuracy: 0.9051\n",
      "Epoch #11 Loss: 0.4900 accuracy: 0.9040\n",
      "Epoch #12 Loss: 0.4826 accuracy: 0.9039\n",
      "Epoch #13 Loss: 0.4766 accuracy: 0.9038\n",
      "Epoch #14 Loss: 0.4706 accuracy: 0.9038\n",
      "Epoch #15 Loss: 0.4661 accuracy: 0.9039\n",
      "Epoch #16 Loss: 0.4607 accuracy: 0.9045\n",
      "Epoch #17 Loss: 0.4571 accuracy: 0.9046\n",
      "Epoch #18 Loss: 0.4525 accuracy: 0.9051\n",
      "Epoch #19 Loss: 0.4489 accuracy: 0.9053\n",
      "Epoch #20 Loss: 0.4452 accuracy: 0.9058\n",
      "Exact match accuracy is: 0.26589315929417456%\n",
      "Macro Area Under the Curve (AUC) is: 0.8700355864313014\n",
      "Micro Area Under the Curve (AUC) is: 0.9137333722313288\n",
      "Weighted Area Under the Curve (AUC) is: 0.8509847225872561\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.10148054145516075\n",
      "saving prediction to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: PosLimited_original_CE_balanced_ratio0.2split_2\n",
      "\n",
      "\n",
      "\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results_balanced/PosLimited_original_CE_balanced_ratio0.2split_2/19-12_17-11\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_resnet_v2_2016_08_30.ckpt\n",
      "Epoch #1 Loss: 0.6071 accuracy: 0.9170\n",
      "Epoch #2 Loss: 0.5642 accuracy: 0.9515\n",
      "Epoch #3 Loss: 0.5548 accuracy: 0.9518\n",
      "Epoch #4 Loss: 0.5421 accuracy: 0.9522\n",
      "Epoch #5 Loss: 0.5255 accuracy: 0.9527\n",
      "Epoch #6 Loss: 0.5057 accuracy: 0.9524\n",
      "Epoch #7 Loss: 0.4857 accuracy: 0.9492\n",
      "Epoch #8 Loss: 0.4691 accuracy: 0.9436\n",
      "Epoch #9 Loss: 0.4560 accuracy: 0.9381\n",
      "Epoch #10 Loss: 0.4461 accuracy: 0.9339\n",
      "Epoch #11 Loss: 0.4376 accuracy: 0.9309\n",
      "Epoch #12 Loss: 0.4312 accuracy: 0.9289\n",
      "Epoch #13 Loss: 0.4255 accuracy: 0.9277\n",
      "Epoch #14 Loss: 0.4206 accuracy: 0.9268\n",
      "Epoch #15 Loss: 0.4166 accuracy: 0.9262\n",
      "Epoch #16 Loss: 0.4121 accuracy: 0.9261\n"
     ]
    }
   ],
   "source": [
    "for split in np.arange(1,5):\n",
    "    for ratio in np.arange(0,1,0.25): \n",
    "        tf.reset_default_graph()\n",
    "        EXPERIMENTNAME = \"PosLimited_original_CE_balanced_ratio\" + str(round(ratio, 1)) + \"split_\" + str(split)\n",
    "        print(\"Current Experiment: \" + EXPERIMENTNAME + \"\\n\\n\\n\")\n",
    "        global_labels = pd.read_csv('/srv/workspace/research/mlml/mlml_weightedLoss/labels_balanced_4labels/missing_labels'+\n",
    "                                    str(round(ratio, 1))+'/train' + str(split) +\"_\" + str(round(ratio, 1)) + '.csv')\n",
    "        # Loading datasets\n",
    "        training_dataset = get_dataset('/srv/workspace/research/mlml/mlml_weightedLoss/labels_balanced_4labels/missing_labels'+\n",
    "                                    str(round(ratio, 1))+'/train' + str(split) +\"_\" + str(round(ratio, 1)) + '.csv')\n",
    "        \n",
    "        global_weights_negative = pd.read_csv('/srv/workspace/research/mlml/mlml_weightedLoss/labels_balanced_4labels/missing_labels'+\n",
    "                            str(round(ratio, 1))+'/negative_weights' + str(split) +\"_\"  + str(round(ratio, 1)) + '.csv')\n",
    "\n",
    "        with tf.Graph().as_default():\n",
    "            # Setting up training generator\n",
    "            training_iterator = training_dataset.make_one_shot_iterator()\n",
    "            training_next_element = training_iterator.get_next()\n",
    "\n",
    "            # Setting up variables\n",
    "            input_labels = tf.placeholder(tf.float32, [None, NUM_CLASSES], name=\"true_labels\")\n",
    "            input_images = tf.placeholder(tf.float32, [None, 224, 224, 3], name=\"input\")\n",
    "            train_phase = tf.placeholder(tf.bool, name=\"is_training\")\n",
    "\n",
    "            # Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "            with slim.arg_scope(inception.inception_resnet_v2_arg_scope()):\n",
    "                ignored_logits, end_points = inception.inception_resnet_v2(input_images, num_classes=NUM_CLASSES, \n",
    "                                                           is_training=train_phase)\n",
    "            \n",
    "            featured_extracted = end_points['Conv2d_7b_1x1']\n",
    "            \n",
    "            with tf.name_scope('trainable/Fully_connected_1'):\n",
    "                flattened = tf.reshape(featured_extracted, [-1, 5*5* 1536])\n",
    "                fully1 = tf.nn.sigmoid(full_layer(flattened, 2048))\n",
    "                \n",
    "            with tf.name_scope('trainable/Fully_connected_2'):\n",
    "                fully2 = tf.nn.sigmoid(full_layer(fully1, 1024))\n",
    "\n",
    "            with tf.name_scope('trainable/Fully_connected_3'):\n",
    "                fully3 = tf.nn.sigmoid(full_layer(fully2, 256)) \n",
    "                \n",
    "            with tf.name_scope('trainable/Fully_connected_4'):\n",
    "                #dropped = tf.nn.dropout(fully1, keep_prob=current_keep_prob)\n",
    "                output_logits = full_layer(fully3, NUM_CLASSES)\n",
    "\n",
    "            trainable_layers = [var for var in tf.global_variables() if (\"trainable\" in var.op.name)]\n",
    "            # Defining loss and metrics\n",
    "            # Define loss and training optimizer\n",
    "            positive_imbalance_weights = tf.constant(Pos_balance_weights)\n",
    "            loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(input_labels,output_logits,\n",
    "                                                                           positive_imbalance_weights))\n",
    "            probabilities = tf.nn.sigmoid(output_logits)\n",
    "\n",
    "            global_step = tf.Variable(0, trainable=False)\n",
    "            learning_rate = tf.train.exponential_decay(learning_rate=0.1, global_step=global_step, decay_steps=1000,\n",
    "                                                      decay_rate=0.95,staircase=True)\n",
    "            train_step = tf.train.AdadeltaOptimizer(learning_rate).minimize(loss,var_list=trainable_layers)\n",
    "\n",
    "            # define accuracy\n",
    "            correct_prediction = tf.equal(tf.round(probabilities), input_labels)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "            # Adding tensorboard summaries\n",
    "            tf.summary.scalar('Original_cross_entropy', loss)\n",
    "            tf.summary.scalar('Accuracy', accuracy)\n",
    "            # Merge all the summaries\n",
    "            merged = tf.summary.merge_all()\n",
    "\n",
    "            # restoring pretrained model weights\n",
    "            checkpoint_exclude_scopes = [\"InceptionResnetV2/Logits\", \"InceptionResnetV2/AuxLogits\"]\n",
    "            exclusions = [scope.strip() for scope in checkpoint_exclude_scopes]\n",
    "            variables_to_restore = []\n",
    "            for var in slim.get_model_variables():\n",
    "                for exclusion in exclusions:\n",
    "                    if var.op.name.startswith(exclusion):\n",
    "                        break\n",
    "                else:\n",
    "                    variables_to_restore.append(var)\n",
    "            init_fn = slim.assign_from_checkpoint_fn(\n",
    "                os.path.join(PRETRAINED_MODEL_DIR, 'inception_resnet_v2_2016_08_30.ckpt'),\n",
    "                variables_to_restore)\n",
    "\n",
    "            # Setting up saving directory\n",
    "            experiment_name = strftime(\"%d-%m_%H-%M\", localtime())\n",
    "            exp_dir = os.path.join(OUTPUT_PATH, EXPERIMENTNAME, experiment_name)\n",
    "\n",
    "            # Add ops to save and restore all the variables.\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                # Write summaries to LOG_DIR -- used by TensorBoard\n",
    "                train_writer = tf.summary.FileWriter(exp_dir + '/tensorboard/train', graph=tf.get_default_graph())\n",
    "                test_writer = tf.summary.FileWriter(exp_dir + '/tensorboard/test', graph=tf.get_default_graph())\n",
    "                print(\"Execute the following in a terminal:\\n\" + \"tensorboard --logdir=\" + exp_dir)\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                init_fn(sess)\n",
    "                for epoch in range(NUM_EPOCHS):\n",
    "                    batch_loss, batch_accuracy = np.zeros([TRAINING_STEPS, 1]), np.zeros([TRAINING_STEPS, 1])\n",
    "                    for batch_counter in range(TRAINING_STEPS):\n",
    "                        batch = sess.run(training_next_element)\n",
    "                        batch_images = batch[0]\n",
    "                        batch_labels = np.squeeze(batch[1])\n",
    "                        summary, batch_loss[batch_counter], batch_accuracy[batch_counter], _ \\\n",
    "                        = sess.run([merged, loss, accuracy, train_step],\n",
    "                                   feed_dict={input_images:batch_images,input_labels:batch_labels,train_phase:True})\n",
    "                    print(\"Epoch #{}\".format(epoch+1), \"Loss: {:.4f}\".format(np.mean(batch_loss)),\n",
    "                          \"accuracy: {:.4f}\".format(np.mean(batch_accuracy)))\n",
    "                    # Add to summaries\n",
    "                    train_writer.add_summary(summary, epoch)\n",
    "                    \n",
    "                os.makedirs(os.path.join(PRETRAINED_MODEL_DIR,EXPERIMENTNAME,experiment_name))\n",
    "                save_path = saver.save(sess, os.path.join(PRETRAINED_MODEL_DIR,EXPERIMENTNAME, \n",
    "                                              experiment_name, \"last_epoch.ckpt\"))\n",
    "                \n",
    "                # Testing the model\n",
    "                test_split = '/srv/workspace/research/mlml/mlml_weightedLoss/labels_balanced_4labels/missing_labels'+ \\\n",
    "                                    str(round(ratio, 1))+'/test' + str(split) + \"_\" + str(round(ratio, 1)) + '.csv'\n",
    "                global_labels = pd.read_csv(test_split)\n",
    "                test_dataset = get_dataset(test_split)\n",
    "                test_classes = np.zeros_like(global_labels.iloc[:,1:].values, dtype=float)\n",
    "\n",
    "                TEST_NUM_STEPS = int(np.floor((len(global_labels)/BATCH_SIZE)))\n",
    "                test_pred_prob = np.zeros_like(test_classes, dtype=float)\n",
    "                test_iterator = test_dataset.make_one_shot_iterator()\n",
    "                test_next_element = test_iterator.get_next()\n",
    "                \n",
    "                for test_batch_counter in range(TEST_NUM_STEPS):\n",
    "                    start_idx = (test_batch_counter * BATCH_SIZE)\n",
    "                    end_idx = (test_batch_counter * BATCH_SIZE) + BATCH_SIZE\n",
    "                    test_batch = sess.run(test_next_element)\n",
    "                    test_batch_images = test_batch[0]\n",
    "                    test_batch_labels = np.squeeze(test_batch[1])\n",
    "                    test_classes[start_idx:end_idx,:] = test_batch_labels\n",
    "                    test_pred_prob[start_idx:end_idx,:] = sess.run(probabilities,\n",
    "                                                             feed_dict={input_images:test_batch_images,train_phase:False})\n",
    "\n",
    "                accuracy_out, auc_roc, hamming_error = evaluate_model(test_pred_prob, test_classes,\n",
    "                                                                  saving_path=exp_dir,\n",
    "                                                                  evaluation_file_path= \\\n",
    "                                                                  os.path.join(exp_dir,\"evaluation_results.txt\"))           \n",
    "                results = create_analysis_report(test_pred_prob, test_classes, exp_dir, LABELS_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
