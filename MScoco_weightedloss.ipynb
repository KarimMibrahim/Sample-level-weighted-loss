{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# General Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import strftime, localtime\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, cohen_kappa_score\n",
    "\n",
    "# [TODO] edit this path to the tfslim directoy \"https://github.com/tensorflow/models/tree/master/research/slim\"\n",
    "SLIM_PATH = '/srv/workspace/research/mlml/models/research/slim'\n",
    "os.chdir(SLIM_PATH)\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from nets import inception\n",
    "from datasets import dataset_utils\n",
    "from preprocessing import inception_preprocessing\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, roc_auc_score, \\\n",
    "    hamming_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "SOURCE_PATH = \"/srv/workspace/research/mlml/mlml_weightedLoss/\"\n",
    "IMAGES_PATH = \"/srv/workspace/research/mlml/datasets/mscoco/train_formatted_npz/\"\n",
    "TEST_IMAGES_PATH = IMAGES_PATH\n",
    "OUTPUT_PATH =\"/srv/workspace/research/mlml/experiments_results/\"\n",
    "PRETRAINED_MODEL_DIR = '/srv/workspace/research/mlml/pretrained_models/'\n",
    "\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "INPUT_IMAGE_MEAN = [0.485, 0.456, 0.406]\n",
    "INPUT_IMAGE_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "labels_set = pd.read_csv('/srv/workspace/research/mlml/mlml_weightedLoss/labels/missing_labels0.0/missing_labels0.0.csv')\n",
    "\n",
    "LABELS_LIST = labels_set.columns\n",
    "NUM_CLASSES = len(LABELS_LIST)\n",
    "\n",
    "# Training paramaeters\n",
    "BATCH_SIZE = 32\n",
    "TRAINING_STEPS = int(len(labels_set)/BATCH_SIZE)\n",
    "NUM_EPOCHS = 5\n",
    "Pos_balance_weights = np.round(1 / (np.sum(labels_set.values, axis = 0)/ len(labels_set))).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     8,
     13,
     19,
     25,
     42,
     49,
     54,
     64,
     100,
     118,
     125,
     136,
     193,
     217,
     237,
     354,
     385,
     408,
     426,
     447,
     473
    ]
   },
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def download_pretrained_model():\n",
    "    url = \"http://download.tensorflow.org/models/inception_v1_2016_08_28.tar.gz\"\n",
    "    if not tf.gfile.Exists(PRETRAINED_MODEL_DIR):\n",
    "        tf.gfile.MakeDirs(PRETRAINED_MODEL_DIR)\n",
    "\n",
    "    dataset_utils.download_and_uncompress_tarball(url, PRETRAINED_MODEL_DIR)\n",
    "\n",
    "def get_weights(shape):\n",
    "    w = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "    return w\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    b = tf.Variable(initial)\n",
    "    return b\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = get_weights([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b\n",
    "\n",
    "def dataset_from_csv(csv_path, **kwargs):\n",
    "    \"\"\"\n",
    "        Load dataset from a csv file.\n",
    "        kwargs are forwarded to the pandas.read_csv function.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, **kwargs)\n",
    "\n",
    "    dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices(\n",
    "            {\n",
    "                key:df[key].values\n",
    "                for key in df\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "def set_tensor_shape(tensor, tensor_shape):\n",
    "        \"\"\"\n",
    "            set shape for a tensor (not in place, as opposed to tf.set_shape)\n",
    "        \"\"\"\n",
    "        tensor.set_shape(tensor_shape)\n",
    "        return tensor\n",
    "\n",
    "def mscoco_labels_idx_to_names(labels,labelnames = LABELS_LIST):\n",
    "    return labelnames[np.where(labels == 1)]\n",
    "\n",
    "\n",
    "# Dataset pipelines\n",
    "def get_weights_py(image_id):\n",
    "    weights_negative = global_weights_negative[global_weights_negative.iloc[:,0] == image_id]\n",
    "    samples_weights_negative = weights_negative.iloc[:, 1:].values.flatten()\n",
    "    samples_weights_negative = samples_weights_negative.astype(np.float32)\n",
    "    return samples_weights_negative\n",
    "\n",
    "def tf_get_weights_py(sample,device = \"/cpu:0\"):\n",
    "    with tf.device(device):\n",
    "        input_args = [sample[\"Unnamed: 0\"]]\n",
    "        negative_weights = tf.py_func(get_weights_py,\n",
    "            input_args,\n",
    "            [tf.float32],\n",
    "            stateful=False)\n",
    "        res = dict(list(sample.items()) + [(\"negative_weights\", negative_weights)])\n",
    "        return res\n",
    "    \n",
    "def load_image_npz(*args):\n",
    "    \"\"\"\n",
    "        loads spectrogram with error tracking.\n",
    "        args : song ID, path to dataset\n",
    "        return:\n",
    "            Features: numpy ndarray, computed features (if no error occured, otherwise: 0)\n",
    "            Error: boolean, False if no error, True if an error was raised during features computation.\n",
    "    \"\"\"\n",
    "    # TODO: edit path\n",
    "    path = IMAGES_PATH\n",
    "    image_id, dummy_path = args\n",
    "    try:\n",
    "        image = np.load(os.path.join(path, str(image_id) + '.npz'))['image']\n",
    "        image = image.astype(np.float32)\n",
    "        image /= 255.0\n",
    "        image = (image - INPUT_IMAGE_MEAN) / INPUT_IMAGE_STD\n",
    "        image = resize(image, INPUT_SHAPE)\n",
    "        image = image.astype(np.float32)\n",
    "        return image, False\n",
    "    except Exception as err:\n",
    "        print(\"\\n Error while computing features for \" + str(image_id) + '\\n')\n",
    "        return np.float32(0.0), True\n",
    "\n",
    "def load_imge_tf(sample, identifier_key=\"Unnamed: 0\",\n",
    "                 path=\"/srv/workspace/research/mlml/datasets/mscoco/train_formatted_npz/\", device=\"/cpu:0\",\n",
    "                 features_key=\"features\"):\n",
    "    \"\"\"\n",
    "        wrap load_images into a tensorflow function.\n",
    "    \"\"\"\n",
    "    with tf.device(device):\n",
    "        input_args = [sample[identifier_key], tf.constant(path)]\n",
    "        res = tf.py_func(load_image_npz,\n",
    "                         input_args,\n",
    "                         (tf.float32, tf.bool),\n",
    "                         stateful=False),\n",
    "        image, error = res[0]\n",
    "        image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "        res = dict(list(sample.items()) + [(features_key, image), (\"error\", error)])\n",
    "        return res\n",
    "\n",
    "# Dataset pipelines\n",
    "def get_labels_py(image_id):\n",
    "    labels = global_labels[global_labels.iloc[:,0] == image_id]\n",
    "    labels = labels.iloc[:, 1:].values.flatten()\n",
    "    labels = labels.astype(np.float32)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def tf_get_labels_py(sample, device=\"/cpu:0\"):\n",
    "    with tf.device(device):\n",
    "        input_args = [sample[\"Unnamed: 0\"]]\n",
    "        labels = tf.py_func(get_labels_py,\n",
    "                            input_args,\n",
    "                            [tf.float32],\n",
    "                            stateful=False)\n",
    "        res = dict(list(sample.items()) + [(\"binary_label\", labels)])\n",
    "        return res\n",
    "\n",
    "\n",
    "def get_dataset(input_csv, input_shape=INPUT_SHAPE, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                infinite_generator=True, random_crop=False,\n",
    "                num_parallel_calls=32):\n",
    "    # build dataset from csv file\n",
    "    dataset = dataset_from_csv(input_csv)\n",
    "    # Shuffle data\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=100, seed=0, reshuffle_each_iteration=True)\n",
    "\n",
    "    # load image\n",
    "    dataset = dataset.map(lambda sample: load_imge_tf(sample), num_parallel_calls=1)\n",
    "\n",
    "    # filter out errors\n",
    "    dataset = dataset.filter(lambda sample: tf.logical_not(sample[\"error\"]))\n",
    "\n",
    "    # set features shape\n",
    "    dataset = dataset.map(lambda sample: dict(sample,\n",
    "                                              features=set_tensor_shape(sample[\"features\"], input_shape)))\n",
    "\n",
    "    dataset = dataset.map(lambda sample: tf_get_labels_py(sample), num_parallel_calls=1)\n",
    "\n",
    "    # set output shape\n",
    "    dataset = dataset.map(lambda sample: dict(sample, binary_label=set_tensor_shape(\n",
    "        sample[\"binary_label\"], (NUM_CLASSES))))\n",
    "    \n",
    "    # load weights\n",
    "    dataset = dataset.map(lambda sample: tf_get_weights_py(sample), num_parallel_calls=1)\n",
    "    \n",
    "    dataset = dataset.map(lambda sample: dict(sample, negative_weights=set_tensor_shape(\n",
    "    sample[\"negative_weights\"], (NUM_CLASSES))))\n",
    "    \n",
    "    if infinite_generator:\n",
    "        # Repeat indefinitly\n",
    "        dataset = dataset.repeat(count=-1)\n",
    "\n",
    "    # Make batch\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Select only features and annotation\n",
    "    dataset = dataset.map(lambda sample: (sample[\"features\"], sample[\"binary_label\"],\n",
    "                                          sample[\"negative_weights\"]))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     8,
     13,
     19,
     25,
     42,
     49,
     54,
     64,
     100,
     118,
     125,
     136,
     193,
     217,
     237,
     354,
     385,
     408,
     426,
     447,
     473
    ]
   },
   "outputs": [],
   "source": [
    "def create_analysis_report(model_output, groundtruth, output_path, LABELS_LIST, validation_output=None,\n",
    "                           validation_groundtruth=None):\n",
    "    \"\"\"\n",
    "    Create a report of all the different evaluation metrics, including optimizing the threshold with the validation set\n",
    "    if it is passed in the parameters\n",
    "    \"\"\"\n",
    "    # Round the probabilities at 0.5\n",
    "    model_output_rounded = np.round(model_output)\n",
    "    model_output_rounded = np.clip(model_output_rounded, 0, 1)\n",
    "    # Create a dataframe where we keep all the evaluations, starting by prediction accuracy\n",
    "    accuracies_perclass = sum(model_output_rounded == groundtruth) / len(groundtruth)\n",
    "    results_df = pd.DataFrame(columns=LABELS_LIST)\n",
    "    results_df.index.astype(str, copy=False)\n",
    "    percentage_of_positives_perclass = sum(groundtruth) / len(groundtruth)\n",
    "    results_df.loc[0] = percentage_of_positives_perclass\n",
    "    results_df.loc[1] = accuracies_perclass\n",
    "    results_df.index = ['Ratio of positive samples', 'Model accuracy']\n",
    "\n",
    "    # plot the accuracies per class\n",
    "    results_df.T.plot.bar(figsize=(22, 12), fontsize=18)\n",
    "    plt.title('Model accuracy vs the ratio of positive samples per class')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(os.path.join(output_path, \"accuracies_vs_positiveRate.pdf\"), format=\"pdf\")\n",
    "    plt.savefig(os.path.join(output_path, \"accuracies_vs_positiveRate.png\"))\n",
    "\n",
    "    # Getting the true positive rate perclass\n",
    "    true_positives_ratio_perclass = sum((model_output_rounded == groundtruth) * (groundtruth == 1)) / sum(groundtruth)\n",
    "    results_df.loc[2] = true_positives_ratio_perclass\n",
    "    # Get true negative ratio\n",
    "    true_negative_ratio_perclass = sum((model_output_rounded == groundtruth)\n",
    "                                       * (groundtruth == 0)) / (len(groundtruth) - sum(groundtruth))\n",
    "    results_df.loc[3] = true_negative_ratio_perclass\n",
    "    # compute additional metrics (AUC,f1,recall,precision)\n",
    "    auc_roc_per_label = roc_auc_score(groundtruth, model_output, average=None)\n",
    "    precision_perlabel = precision_score(groundtruth, model_output_rounded, average=None)\n",
    "    recall_perlabel = recall_score(groundtruth, model_output_rounded, average=None)\n",
    "    f1_perlabel = f1_score(groundtruth, model_output_rounded, average=None)\n",
    "    kappa_perlabel = [cohen_kappa_score(groundtruth[:, x], model_output_rounded[:, x]) for x in range(len(LABELS_LIST))]\n",
    "    results_df = results_df.append(\n",
    "        pd.DataFrame([auc_roc_per_label,recall_perlabel, precision_perlabel, f1_perlabel, kappa_perlabel], columns=LABELS_LIST))\n",
    "    results_df.index = ['Ratio of positive samples', 'Model accuracy', 'True positives ratio',\n",
    "                        'True negatives ratio', \"AUC\", \"Recall\", \"Precision\", \"f1-score\", \"Kappa score\"]\n",
    "\n",
    "    # Adjusting threshold based on validation set\n",
    "    if (validation_groundtruth is not None and validation_output is not None):\n",
    "        np.savetxt(os.path.join(output_path, 'validation_predictions.out'), validation_output, delimiter=',')\n",
    "        np.savetxt(os.path.join(output_path, 'valid_ground_truth_classes.txt'), validation_groundtruth, delimiter=',')\n",
    "        thresholds = np.arange(0, 1, 0.01)\n",
    "        f1_array = np.zeros((len(LABELS_LIST), len(thresholds)))\n",
    "        for idx, label in enumerate(LABELS_LIST):\n",
    "            f1_array[idx, :] = [\n",
    "                f1_score(validation_groundtruth[:, idx], np.clip(np.round(validation_output[:, idx] - threshold + 0.5), 0, 1))\n",
    "                for threshold in thresholds]\n",
    "        threshold_arg = np.argmax(f1_array, axis=1)\n",
    "        threshold_per_class = thresholds[threshold_arg]\n",
    "\n",
    "        # plot the f1 score across thresholds\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        for idx, x in enumerate(LABELS_LIST):\n",
    "            plt.plot(thresholds, f1_array[idx, :], linewidth=5)\n",
    "        plt.legend(LABELS_LIST, loc='best')\n",
    "        plt.title(\"F1 Score vs different prediction threshold values for each class\")\n",
    "        plt.savefig(os.path.join(output_path, \"f1_score_vs_thresholds.pdf\"), format=\"pdf\")\n",
    "        plt.savefig(os.path.join(output_path, \"f1_score_vs_thresholds.png\"))\n",
    "\n",
    "        # Applying thresholds optimized per class\n",
    "        model_output_rounded = np.zeros_like(model_output)\n",
    "        for idx, label in enumerate(LABELS_LIST):\n",
    "            model_output_rounded[:, idx] = np.clip(np.round(model_output[:, idx] - threshold_per_class[idx] + 0.5), 0, 1)\n",
    "\n",
    "        accuracies_perclass = sum(model_output_rounded == groundtruth) / len(groundtruth)\n",
    "        # Getting the true positive rate perclass\n",
    "        true_positives_ratio_perclass = sum((model_output_rounded == groundtruth) * (groundtruth == 1)) / sum(\n",
    "            groundtruth)\n",
    "        # Get true negative ratio\n",
    "        true_negative_ratio_perclass = sum((model_output_rounded == groundtruth)\n",
    "                                           * (groundtruth == 0)) / (len(groundtruth) - sum(groundtruth))\n",
    "        results_df = results_df.append(\n",
    "            pd.DataFrame([accuracies_perclass, true_positives_ratio_perclass,\n",
    "                          true_negative_ratio_perclass], columns=LABELS_LIST))\n",
    "        # compute additional metrics (AUC,f1,recall,precision)\n",
    "        auc_roc_per_label = roc_auc_score(groundtruth, model_output, average=None)\n",
    "        precision_perlabel = precision_score(groundtruth, model_output_rounded, average=None)\n",
    "        recall_perlabel = recall_score(groundtruth, model_output_rounded, average=None)\n",
    "        f1_perlabel = f1_score(groundtruth, model_output_rounded, average=None)\n",
    "        kappa_perlabel = [cohen_kappa_score(groundtruth[:, x], model_output_rounded[:, x]) for x in\n",
    "                          range(len(LABELS_LIST))]\n",
    "        results_df = results_df.append(\n",
    "            pd.DataFrame([auc_roc_per_label,recall_perlabel, precision_perlabel, f1_perlabel,kappa_perlabel],\n",
    "                         columns=LABELS_LIST))\n",
    "        results_df.index = ['Ratio of positive samples', 'Model accuracy', 'True positives ratio',\n",
    "                            'True negatives ratio', \"AUC\", \"Precision\", \"Recall\", \"f1-score\",  \"Kappa score\",\n",
    "                            'Optimized model accuracy', 'Optimized true positives ratio',\n",
    "                            'Optimized true negatives ratio', \"Optimized AUC\",\n",
    "                            \"Optimized precision\", \"Optimized recall\", \"Optimized f1-score\",  \"Optimized Kappa score\"]\n",
    "\n",
    "    results_df['average'] = results_df.mean(numeric_only=True, axis=1)\n",
    "    results_df.T.to_csv(os.path.join(output_path, \"results_report.csv\"), float_format=\"%.2f\")\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def evaluate_model(test_pred_prob, test_classes, saving_path, evaluation_file_path):\n",
    "    \"\"\"\n",
    "    Evaluates a given model using accuracy, area under curve and hamming loss\n",
    "    :param model: model to be evaluated\n",
    "    :param spectrograms: the test set spectrograms as an np.array\n",
    "    :param test_classes: the ground truth labels\n",
    "    :return: accuracy, auc_roc, hamming_error\n",
    "    \"\"\"\n",
    "    test_pred = np.round(test_pred_prob)\n",
    "    # Accuracy\n",
    "    accuracy = 100 * accuracy_score(test_classes, test_pred)\n",
    "    print(\"Exact match accuracy is: \" + str(accuracy) + \"%\")\n",
    "    # Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
    "    auc_roc = roc_auc_score(test_classes, test_pred_prob)\n",
    "    print(\"Macro Area Under the Curve (AUC) is: \" + str(auc_roc))\n",
    "    auc_roc_micro = roc_auc_score(test_classes, test_pred_prob, average=\"micro\")\n",
    "    print(\"Micro Area Under the Curve (AUC) is: \" + str(auc_roc_micro))\n",
    "    auc_roc_weighted = roc_auc_score(test_classes, test_pred_prob, average=\"weighted\")\n",
    "    print(\"Weighted Area Under the Curve (AUC) is: \" + str(auc_roc_weighted))\n",
    "    # Hamming loss is the fraction of labels that are incorrectly predicted.\n",
    "    hamming_error = hamming_loss(test_classes, test_pred)\n",
    "    print(\"Hamming Loss (ratio of incorrect tags) is: \" + str(hamming_error))\n",
    "    with open(evaluation_file_path, \"w\") as f:\n",
    "        f.write(\"Exact match accuracy is: \" + str(accuracy) + \"%\\n\" + \"Area Under the Curve (AUC) is: \" + str(auc_roc)\n",
    "                + \"\\nMicro AUC is:\" + str(auc_roc_micro) + \"\\nWeighted AUC is:\" + str(auc_roc_weighted)\n",
    "                + \"\\nHamming Loss (ratio of incorrect tags) is: \" + str(hamming_error))\n",
    "    print(\"saving prediction to disk\")\n",
    "    np.savetxt(os.path.join(saving_path, 'predictions.out'), test_pred_prob, delimiter=',')\n",
    "    np.savetxt(os.path.join(saving_path, 'test_ground_truth_classes.txt'), test_classes, delimiter=',')\n",
    "    return accuracy, auc_roc, hamming_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     1,
     8,
     13,
     19,
     25,
     42,
     49,
     54,
     64,
     100,
     118,
     125,
     136,
     193,
     217,
     237,
     354,
     385,
     408,
     426,
     447,
     473
    ]
   },
   "outputs": [],
   "source": [
    "def weighted_loss(y_true, y_pred, positive_weights, negative_weights):\n",
    "    # clip to prevent NaN's and Inf's\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1-1e-7, name=None)\n",
    "    #y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # calc\n",
    "    loss = (-y_true * tf.log(y_pred) * positive_weights) - ((1.0 - y_true) * tf.log(1.0 - y_pred) * negative_weights)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine-tune pretrained model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: weighted_CE_ratio0.0split_1\n",
      "\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary name Weighted cross entropy is illegal; using Weighted_cross_entropy instead.\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results/weighted_CE_ratio0.0split_1/14-12_15-10\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_v1.ckpt\n",
      "Epoch #1 Loss: 1.1443 accuracy: 0.6862\n",
      "Epoch #2 Loss: 0.8454 accuracy: 0.8167\n",
      "Epoch #3 Loss: 0.7388 accuracy: 0.8415\n",
      "Epoch #4 Loss: 0.6832 accuracy: 0.8533\n",
      "Epoch #5 Loss: 0.6475 accuracy: 0.8610\n",
      "Exact match accuracy is: 0.7987711213517665%\n",
      "Macro Area Under the Curve (AUC) is: 0.9236844723372624\n",
      "Micro Area Under the Curve (AUC) is: 0.9378965579710195\n",
      "Weighted Area Under the Curve (AUC) is: 0.9063294168271168\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.1370532514080901\n",
      "saving prediction to disk\n",
      "Current Experiment: weighted_CE_ratio0.2split_1\n",
      "\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary name Weighted cross entropy is illegal; using Weighted_cross_entropy instead.\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results/weighted_CE_ratio0.2split_1/14-12_19-37\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_v1.ckpt\n",
      "Epoch #1 Loss: 1.0433 accuracy: 0.7534\n",
      "Epoch #2 Loss: 0.7756 accuracy: 0.8489\n",
      "Epoch #3 Loss: 0.6770 accuracy: 0.8636\n",
      "Epoch #4 Loss: 0.6237 accuracy: 0.8722\n",
      "Epoch #5 Loss: 0.5925 accuracy: 0.8773\n",
      "Exact match accuracy is: 1.0820959208055982%\n",
      "Macro Area Under the Curve (AUC) is: 0.922474763196582\n",
      "Micro Area Under the Curve (AUC) is: 0.9373222354441029\n",
      "Weighted Area Under the Curve (AUC) is: 0.9053343232183424\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.11739972691585594\n",
      "saving prediction to disk\n",
      "Current Experiment: weighted_CE_ratio0.4split_1\n",
      "\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary name Weighted cross entropy is illegal; using Weighted_cross_entropy instead.\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results/weighted_CE_ratio0.4split_1/15-12_00-01\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_v1.ckpt\n",
      "Epoch #1 Loss: 0.9260 accuracy: 0.8476\n",
      "Epoch #2 Loss: 0.7022 accuracy: 0.8936\n",
      "Epoch #3 Loss: 0.6080 accuracy: 0.8960\n",
      "Epoch #4 Loss: 0.5571 accuracy: 0.8982\n",
      "Epoch #5 Loss: 0.5242 accuracy: 0.9002\n",
      "Exact match accuracy is: 2.0447175285884964%\n",
      "Macro Area Under the Curve (AUC) is: 0.9198678822334511\n",
      "Micro Area Under the Curve (AUC) is: 0.9351199725619176\n",
      "Weighted Area Under the Curve (AUC) is: 0.9022251719052384\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.09364994026284348\n",
      "saving prediction to disk\n",
      "Current Experiment: weighted_CE_ratio0.6split_1\n",
      "\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary name Weighted cross entropy is illegal; using Weighted_cross_entropy instead.\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results/weighted_CE_ratio0.6split_1/15-12_04-26\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_v1.ckpt\n",
      "Epoch #1 Loss: 0.7309 accuracy: 0.9370\n",
      "Epoch #2 Loss: 0.5855 accuracy: 0.9515\n",
      "Epoch #3 Loss: 0.5127 accuracy: 0.9402\n",
      "Epoch #4 Loss: 0.4672 accuracy: 0.9346\n",
      "Epoch #5 Loss: 0.4389 accuracy: 0.9323\n",
      "Exact match accuracy is: 4.495647721454174%\n",
      "Macro Area Under the Curve (AUC) is: 0.9084844716609795\n",
      "Micro Area Under the Curve (AUC) is: 0.9264142079206278\n",
      "Weighted Area Under the Curve (AUC) is: 0.8932565992589516\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.06582181259600614\n",
      "saving prediction to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: weighted_CE_ratio0.8split_1\n",
      "\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary name Weighted cross entropy is illegal; using Weighted_cross_entropy instead.\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results/weighted_CE_ratio0.8split_1/15-12_08-54\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_v1.ckpt\n",
      "Epoch #1 Loss: 0.4662 accuracy: 0.9758\n",
      "Epoch #2 Loss: 0.3966 accuracy: 0.9908\n",
      "Epoch #3 Loss: 0.3597 accuracy: 0.9858\n",
      "Epoch #4 Loss: 0.3304 accuracy: 0.9808\n",
      "Epoch #5 Loss: 0.3083 accuracy: 0.9770\n",
      "Exact match accuracy is: 2.048131080389145%\n",
      "Macro Area Under the Curve (AUC) is: 0.8627380792761077\n",
      "Micro Area Under the Curve (AUC) is: 0.8918525547805205\n",
      "Weighted Area Under the Curve (AUC) is: 0.8610646645922002\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.03789938556067588\n",
      "saving prediction to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: weighted_CE_ratio0.0split_2\n",
      "\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary name Weighted cross entropy is illegal; using Weighted_cross_entropy instead.\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results/weighted_CE_ratio0.0split_2/15-12_13-18\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_v1.ckpt\n",
      "Epoch #1 Loss: 1.1382 accuracy: 0.6887\n",
      "Epoch #2 Loss: 0.8374 accuracy: 0.8212\n",
      "Epoch #3 Loss: 0.7349 accuracy: 0.8434\n",
      "Epoch #4 Loss: 0.6809 accuracy: 0.8542\n",
      "Epoch #5 Loss: 0.6465 accuracy: 0.8614\n",
      "Exact match accuracy is: 0.6460654953168797%\n",
      "Macro Area Under the Curve (AUC) is: 0.9226805418736234\n",
      "Micro Area Under the Curve (AUC) is: 0.9362047660651625\n",
      "Weighted Area Under the Curve (AUC) is: 0.9040611820609085\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.13461535174676967\n",
      "saving prediction to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: weighted_CE_ratio0.2split_2\n",
      "\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary name Weighted cross entropy is illegal; using Weighted_cross_entropy instead.\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results/weighted_CE_ratio0.2split_2/15-12_17-46\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_v1.ckpt\n",
      "Epoch #1 Loss: 1.0507 accuracy: 0.7561\n",
      "Epoch #2 Loss: 0.7816 accuracy: 0.8481\n",
      "Epoch #3 Loss: 0.6803 accuracy: 0.8639\n",
      "Epoch #4 Loss: 0.6268 accuracy: 0.8719\n",
      "Epoch #5 Loss: 0.5938 accuracy: 0.8774\n",
      "Exact match accuracy is: 1.0870308333903056%\n",
      "Macro Area Under the Curve (AUC) is: 0.9205324064331162\n",
      "Micro Area Under the Curve (AUC) is: 0.9345542284451157\n",
      "Weighted Area Under the Curve (AUC) is: 0.9024227394001353\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.11617129281465782\n",
      "saving prediction to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: weighted_CE_ratio0.4split_2\n",
      "\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary name Weighted cross entropy is illegal; using Weighted_cross_entropy instead.\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results/weighted_CE_ratio0.4split_2/15-12_22-11\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_v1.ckpt\n",
      "Epoch #1 Loss: 0.9269 accuracy: 0.8475\n",
      "Epoch #2 Loss: 0.6985 accuracy: 0.8932\n",
      "Epoch #3 Loss: 0.6059 accuracy: 0.8953\n",
      "Epoch #4 Loss: 0.5540 accuracy: 0.8982\n",
      "Epoch #5 Loss: 0.5229 accuracy: 0.9002\n",
      "Exact match accuracy is: 2.310795104942914%\n",
      "Macro Area Under the Curve (AUC) is: 0.919449152223482\n",
      "Micro Area Under the Curve (AUC) is: 0.9339617294968425\n",
      "Weighted Area Under the Curve (AUC) is: 0.9011056765464368\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.09339192930881247\n",
      "saving prediction to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: weighted_CE_ratio0.6split_2\n",
      "\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary name Weighted cross entropy is illegal; using Weighted_cross_entropy instead.\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results/weighted_CE_ratio0.6split_2/16-12_02-42\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_v1.ckpt\n",
      "Epoch #1 Loss: 0.7273 accuracy: 0.9445\n",
      "Epoch #2 Loss: 0.5821 accuracy: 0.9511\n",
      "Epoch #3 Loss: 0.5063 accuracy: 0.9402\n",
      "Epoch #4 Loss: 0.4613 accuracy: 0.9355\n",
      "Epoch #5 Loss: 0.4315 accuracy: 0.9333\n",
      "Exact match accuracy is: 4.683120257058864%\n",
      "Macro Area Under the Curve (AUC) is: 0.9093511750134031\n",
      "Micro Area Under the Curve (AUC) is: 0.9255430276583076\n",
      "Weighted Area Under the Curve (AUC) is: 0.8909866183847662\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.06453861010460107\n",
      "saving prediction to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: weighted_CE_ratio0.8split_2\n",
      "\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary name Weighted cross entropy is illegal; using Weighted_cross_entropy instead.\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results/weighted_CE_ratio0.8split_2/16-12_07-11\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_v1.ckpt\n",
      "Epoch #1 Loss: 0.4690 accuracy: 0.9762\n",
      "Epoch #2 Loss: 0.4046 accuracy: 0.9914\n",
      "Epoch #3 Loss: 0.3637 accuracy: 0.9872\n",
      "Epoch #4 Loss: 0.3333 accuracy: 0.9823\n",
      "Epoch #5 Loss: 0.3122 accuracy: 0.9781\n",
      "Exact match accuracy is: 2.1603883229643808%\n",
      "Macro Area Under the Curve (AUC) is: 0.8597628663402512\n",
      "Micro Area Under the Curve (AUC) is: 0.8881737082748263\n",
      "Weighted Area Under the Curve (AUC) is: 0.857939412470936\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.037614086962466674\n",
      "saving prediction to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: weighted_CE_ratio0.0split_3\n",
      "\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary name Weighted cross entropy is illegal; using Weighted_cross_entropy instead.\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results/weighted_CE_ratio0.0split_3/16-12_11-34\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_v1.ckpt\n",
      "Epoch #1 Loss: 1.1329 accuracy: 0.6979\n",
      "Epoch #2 Loss: 0.8372 accuracy: 0.8224\n",
      "Epoch #3 Loss: 0.7343 accuracy: 0.8436\n",
      "Epoch #4 Loss: 0.6799 accuracy: 0.8550\n",
      "Epoch #5 Loss: 0.6469 accuracy: 0.8620\n",
      "Exact match accuracy is: 0.5654143533499097%\n",
      "Macro Area Under the Curve (AUC) is: 0.9246730997310525\n",
      "Micro Area Under the Curve (AUC) is: 0.9385717508490926\n",
      "Weighted Area Under the Curve (AUC) is: 0.9065649476862961\n",
      "Hamming Loss (ratio of incorrect tags) is: 0.14029854559078989\n",
      "saving prediction to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiment: weighted_CE_ratio0.2split_3\n",
      "\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary name Weighted cross entropy is illegal; using Weighted_cross_entropy instead.\n",
      "Execute the following in a terminal:\n",
      "tensorboard --logdir=/srv/workspace/research/mlml/experiments_results/weighted_CE_ratio0.2split_3/16-12_15-57\n",
      "INFO:tensorflow:Restoring parameters from /srv/workspace/research/mlml/pretrained_models/inception_v1.ckpt\n",
      "Epoch #1 Loss: 1.0423 accuracy: 0.7595\n"
     ]
    }
   ],
   "source": [
    "for split in np.arange(1,5):\n",
    "    for ratio in np.arange(0,1,0.2): \n",
    "        tf.reset_default_graph()\n",
    "        EXPERIMENTNAME = \"weighted_CE_ratio\" + str(round(ratio, 1)) + \"split_\" + str(split)\n",
    "        print(\"Current Experiment: \" + EXPERIMENTNAME + \"\\n\\n\\n\")\n",
    "        global_labels = pd.read_csv('/srv/workspace/research/mlml/mlml_weightedLoss/labels/missing_labels'+\n",
    "                                    str(round(ratio, 1))+'/train' + str(split) +\"_\" + str(round(ratio, 1)) + '.csv')\n",
    "        global_weights_negative = pd.read_csv('/srv/workspace/research/mlml/mlml_weightedLoss/labels/missing_labels'+\n",
    "                                    str(round(ratio, 1))+'/negative_weights' + str(split) +\"_\"  + str(round(ratio, 1)) + '.csv')\n",
    "        # Loading datasets\n",
    "        training_dataset = get_dataset('/srv/workspace/research/mlml/mlml_weightedLoss/labels/missing_labels'+\n",
    "                                    str(round(ratio, 1))+'/train' + str(split) +\"_\" + str(round(ratio, 1)) + '.csv')\n",
    "        with tf.Graph().as_default():\n",
    "            # Setting up training generator\n",
    "            training_iterator = training_dataset.make_one_shot_iterator()\n",
    "            training_next_element = training_iterator.get_next()\n",
    "\n",
    "            # Setting up variables\n",
    "            input_labels = tf.placeholder(tf.float32, [None, NUM_CLASSES], name=\"true_labels\")\n",
    "            negative_weights = tf.placeholder(tf.float32, [None, NUM_CLASSES], name=\"negative_weights\")\n",
    "            input_images = tf.placeholder(tf.float32, [None, 224, 224, 3], name=\"input\")\n",
    "            train_phase = tf.placeholder(tf.bool, name=\"is_training\")\n",
    "\n",
    "            # Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "            with slim.arg_scope(inception.inception_v1_arg_scope()):\n",
    "                ignored_logits, end_points = inception.inception_v1(input_images, num_classes=NUM_CLASSES, \n",
    "                                                           is_training=train_phase)\n",
    "\n",
    "            featured_extracted = end_points['Mixed_5c']\n",
    "\n",
    "            with tf.name_scope('trainable/Fully_connected_1'):\n",
    "                flattened = tf.reshape(featured_extracted, [-1, 7*7* 1024])\n",
    "                fully1 = tf.nn.sigmoid(full_layer(flattened, 256))\n",
    "\n",
    "            with tf.name_scope('trainable/Fully_connected_2'):\n",
    "                #dropped = tf.nn.dropout(fully1, keep_prob=current_keep_prob)\n",
    "                output_logits = full_layer(fully1, NUM_CLASSES)\n",
    "            \n",
    "            probabilities = tf.nn.sigmoid(output_logits)\n",
    "            tf.summary.histogram('outputs', probabilities)\n",
    "\n",
    "            trainable_layers = [var for var in tf.global_variables() if (\"trainable\" in var.op.name)]\n",
    "            positive_imbalance_weights = tf.constant(Pos_balance_weights)\n",
    "            loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(input_labels,output_logits,\n",
    "                                                                           positive_imbalance_weights))\n",
    "            \n",
    "            my_weights_loss = weighted_loss(y_true= input_labels, y_pred= probabilities,\n",
    "                              positive_weights= positive_imbalance_weights, negative_weights= negative_weights)\n",
    "                \n",
    "\n",
    "\n",
    "            global_step = tf.Variable(0, trainable=False)\n",
    "            learning_rate = tf.train.exponential_decay(learning_rate=0.1, global_step=global_step,\n",
    "                                                       decay_steps=1000,\n",
    "                                                      decay_rate=0.95,staircase=True)\n",
    "            train_step = tf.train.AdadeltaOptimizer(learning_rate).minimize(my_weights_loss,\n",
    "                                                                            var_list=trainable_layers)\n",
    "            \n",
    "            # define accuracy\n",
    "            correct_prediction = tf.equal(tf.round(probabilities), input_labels)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "            # Adding tensorboard summaries\n",
    "            tf.summary.scalar('Original_cross_entropy', loss)\n",
    "            tf.summary.scalar('Weighted cross entropy',  my_weights_loss)\n",
    "            tf.summary.scalar('Accuracy', accuracy)\n",
    "            # Merge all the summaries\n",
    "            merged = tf.summary.merge_all()\n",
    "\n",
    "            # restoring pretrained model weights\n",
    "            checkpoint_exclude_scopes = [\"InceptionV1/Logits\", \"InceptionV1/AuxLogits\"]\n",
    "            exclusions = [scope.strip() for scope in checkpoint_exclude_scopes]\n",
    "            variables_to_restore = []\n",
    "            for var in slim.get_model_variables():\n",
    "                for exclusion in exclusions:\n",
    "                    if var.op.name.startswith(exclusion):\n",
    "                        break\n",
    "                else:\n",
    "                    variables_to_restore.append(var)\n",
    "            init_fn = slim.assign_from_checkpoint_fn(\n",
    "                os.path.join(PRETRAINED_MODEL_DIR, 'inception_v1.ckpt'),\n",
    "                variables_to_restore)\n",
    "\n",
    "            # Setting up saving directory\n",
    "            experiment_name = strftime(\"%d-%m_%H-%M\", localtime())\n",
    "            exp_dir = os.path.join(OUTPUT_PATH, EXPERIMENTNAME, experiment_name)\n",
    "\n",
    "            # Add ops to save and restore all the variables.\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            epoch_losses_history, epoch_accurcies_history, val_losses_history, val_accuracies_history = [], [], [], []\n",
    "            #my_loss_history, my_loss_val_history = [], []\n",
    "            with tf.Session() as sess:\n",
    "                # Write summaries to LOG_DIR -- used by TensorBoard\n",
    "                train_writer = tf.summary.FileWriter(exp_dir + '/tensorboard/train', graph=tf.get_default_graph())\n",
    "                test_writer = tf.summary.FileWriter(exp_dir + '/tensorboard/test', graph=tf.get_default_graph())\n",
    "                print(\"Execute the following in a terminal:\\n\" + \"tensorboard --logdir=\" + exp_dir)\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                init_fn(sess)\n",
    "                for epoch in range(NUM_EPOCHS):\n",
    "                    batch_loss, batch_accuracy = np.zeros([TRAINING_STEPS, 1]), np.zeros([TRAINING_STEPS, 1])\n",
    "                    #batch_my_loss, val_my_loss = np.zeros([TRAINING_STEPS, 1]), np.zeros([VALIDATION_STEPS, 1])\n",
    "                    #val_accuracies, val_losses = np.zeros([VALIDATION_STEPS, 1]), np.zeros([VALIDATION_STEPS, 1])\n",
    "                    for batch_counter in range(TRAINING_STEPS):\n",
    "                        batch = sess.run(training_next_element)\n",
    "                        batch_images = batch[0]\n",
    "                        batch_labels = np.squeeze(batch[1])\n",
    "                        batch_negative_weights = np.squeeze(batch[2])\n",
    "                        summary, batch_loss[batch_counter], batch_accuracy[batch_counter], _ \\\n",
    "                        = sess.run([merged, my_weights_loss, accuracy, train_step],\n",
    "                                   feed_dict={input_images:batch_images,\n",
    "                                              input_labels:batch_labels,\n",
    "                                              negative_weights: batch_negative_weights,\n",
    "                                              train_phase:True})\n",
    "                    print(\"Epoch #{}\".format(epoch+1), \"Loss: {:.4f}\".format(np.mean(batch_loss)),\n",
    "                          \"accuracy: {:.4f}\".format(np.mean(batch_accuracy)))\n",
    "                    epoch_losses_history.append(np.mean(batch_loss))\n",
    "                    epoch_accurcies_history.append(np.mean(batch_accuracy))\n",
    "                    #my_loss_history.append(np.mean(batch_my_loss))\n",
    "                    # Add to summaries\n",
    "                    train_writer.add_summary(summary, epoch)\n",
    "                    \n",
    "                os.makedirs(os.path.join(PRETRAINED_MODEL_DIR,EXPERIMENTNAME,experiment_name))\n",
    "                save_path = saver.save(sess, os.path.join(PRETRAINED_MODEL_DIR,EXPERIMENTNAME, \n",
    "                                              experiment_name, \"last_epoch.ckpt\"))\n",
    "                \n",
    "                # Testing the model\n",
    "                test_split = '/srv/workspace/research/mlml/mlml_weightedLoss/labels/missing_labels'+ \\\n",
    "                                    str(round(ratio, 1))+'/test' + str(split) + \"_\" + str(round(ratio, 1)) + '.csv'\n",
    "                global_labels = pd.read_csv(test_split)\n",
    "                test_dataset = get_dataset(test_split)\n",
    "                test_classes = np.zeros_like(global_labels.iloc[:,1:].values, dtype=float)\n",
    "                #test_images, test_classes = load_test_set_raw(test_split)\n",
    "\n",
    "                TEST_NUM_STEPS = int(np.floor((len(global_labels)/BATCH_SIZE)))\n",
    "                #split_size = int(len(test_classes) / TEST_NUM_STEPS)\n",
    "                test_pred_prob = np.zeros_like(test_classes, dtype=float)\n",
    "                test_iterator = test_dataset.make_one_shot_iterator()\n",
    "                test_next_element = test_iterator.get_next()\n",
    "                \n",
    "                for test_batch_counter in range(TEST_NUM_STEPS):\n",
    "                    start_idx = (test_batch_counter * BATCH_SIZE)\n",
    "                    end_idx = (test_batch_counter * BATCH_SIZE) + BATCH_SIZE\n",
    "                    test_batch = sess.run(test_next_element)\n",
    "                    test_batch_images = test_batch[0]\n",
    "                    test_batch_labels = np.squeeze(test_batch[1])\n",
    "                    test_classes[start_idx:end_idx,:] = test_batch_labels\n",
    "                    test_pred_prob[start_idx:end_idx,:] = sess.run(probabilities,\n",
    "                                                             feed_dict={input_images:test_batch_images,train_phase:False})\n",
    "\n",
    "                accuracy_out, auc_roc, hamming_error = evaluate_model(test_pred_prob, test_classes,\n",
    "                                                                  saving_path=exp_dir,\n",
    "                                                                  evaluation_file_path= \\\n",
    "                                                                  os.path.join(exp_dir,\"evaluation_results.txt\"))           \n",
    "                results = create_analysis_report(test_pred_prob, test_classes, exp_dir, LABELS_LIST)\n",
    "\n",
    "            # Plot and save losses\n",
    "            plot_loss_acuracy(epoch_losses_history, epoch_accurcies_history,val_losses_history, \n",
    "                              val_accuracies_history,exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# testing model\n",
    "EXPERIMENTNAME = \"original_CE_ratio\" + str(round(0.0, 1)) + \"split_\" + str(1)\n",
    "print(\"Current Experiment: \" + EXPERIMENTNAME + \"\\n\\n\\n\")\n",
    "# Setting up saving directory\n",
    "experiment_name = '2019-12-11_00-22-05'\n",
    "exp_dir = os.path.join(OUTPUT_PATH, EXPERIMENTNAME, experiment_name)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    # Setting up variables\n",
    "    input_labels = tf.placeholder(tf.float32, [None, NUM_CLASSES], name=\"true_labels\")\n",
    "    input_images = tf.placeholder(tf.float32, [None, 224, 224, 3], name=\"input\")\n",
    "    train_phase = tf.placeholder(tf.bool, name=\"is_training\")\n",
    "\n",
    "    # Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "    with slim.arg_scope(inception.inception_v1_arg_scope()):\n",
    "        ignored_logits, end_points = inception.inception_v1(input_images, num_classes=NUM_CLASSES, \n",
    "                                                   is_training=train_phase)\n",
    "\n",
    "    featured_extracted = end_points['Mixed_5c']\n",
    "\n",
    "    with tf.name_scope('trainable/Fully_connected_1'):\n",
    "        flattened = tf.reshape(featured_extracted, [-1, 7*7* 1024])\n",
    "        fully1 = tf.nn.sigmoid(full_layer(flattened, 256))\n",
    "\n",
    "    with tf.name_scope('trainable/Fully_connected_2'):\n",
    "        #dropped = tf.nn.dropout(fully1, keep_prob=current_keep_prob)\n",
    "        output_logits = full_layer(fully1, NUM_CLASSES)\n",
    "\n",
    "    trainable_layers = [var for var in tf.global_variables() if (\"trainable\" in var.op.name)]\n",
    "    # Defining loss and metrics\n",
    "    # Define loss and training optimizer\n",
    "    #loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=output_logits, labels=input_labels))\n",
    "    positive_imbalance_weights = tf.constant(Pos_balance_weights)\n",
    "    loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(input_labels,output_logits,\n",
    "                                                                   positive_imbalance_weights))\n",
    "    probabilities = tf.nn.sigmoid(output_logits)\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate=0.1, global_step=global_step, decay_steps=1000,\n",
    "                                              decay_rate=0.95,staircase=True)\n",
    "    train_step = tf.train.AdadeltaOptimizer(learning_rate).minimize(loss,var_list=trainable_layers)\n",
    "    #my_weights_loss = weighted_loss(y_true= y, y_pred= model_output,\n",
    "    #                             positive_weights= positive_weights, negative_weights= negative_weights)\n",
    "\n",
    "    # define accuracy\n",
    "    correct_prediction = tf.equal(tf.round(probabilities), input_labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "    test_split = '/srv/workspace/research/mlml/mlml_weightedLoss/labels/missing_labels'+ \\\n",
    "                        str(round(0.0, 1))+'/test' + str(1) + \"_\" + str(round(0.0, 1)) + '.csv'\n",
    "    global_labels = pd.read_csv(test_split)\n",
    "    test_dataset = get_dataset(test_split)\n",
    "    test_classes = np.zeros_like(global_labels.iloc[:,1:].values, dtype=float)\n",
    "    #test_images, test_classes = load_test_set_raw(test_split)\n",
    "\n",
    "    TEST_NUM_STEPS = int(np.floor((len(global_labels)/BATCH_SIZE))) # number is chosen based on testset size to be dividable\n",
    "    test_pred_prob = np.zeros_like(test_classes, dtype=float)\n",
    "    test_iterator = test_dataset.make_one_shot_iterator()\n",
    "    test_next_element = test_iterator.get_next()\n",
    "\n",
    "    SAVED_MODEL_PATH = os.path.join(PRETRAINED_MODEL_DIR,\n",
    "                                    'original_CE_ratio0.2split_1/2019-12-11_00-22-05',\"last_epoch.ckpt\")\n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        #sess.run(tf.global_variables_initializer())\n",
    "        #init_fn(sess)     \n",
    "        saver.restore(sess, SAVED_MODEL_PATH)\n",
    "        print(\"Model with best validation restored before testing.\")\n",
    "                \n",
    "        for test_batch_counter in range(TEST_NUM_STEPS):\n",
    "            start_idx = (test_batch_counter * BATCH_SIZE)\n",
    "            end_idx = (test_batch_counter * BATCH_SIZE) + BATCH_SIZE\n",
    "            test_batch = sess.run(test_next_element)\n",
    "            test_batch_images = test_batch[0]\n",
    "            test_batch_labels = np.squeeze(test_batch[1])\n",
    "            test_classes[start_idx:end_idx,:] = test_batch_labels\n",
    "            test_pred_prob[start_idx:end_idx,:] = sess.run(probabilities,\n",
    "                                                     feed_dict={input_images:test_batch_images,train_phase:False})\n",
    "            if(test_batch_counter%1000 == 0):\n",
    "                print(test_batch_counter)\n",
    "        accuracy, auc_roc, hamming_error = evaluate_model(test_pred_prob, test_classes,\n",
    "                                                          saving_path=exp_dir,\n",
    "                                                          evaluation_file_path= \\\n",
    "                                                          os.path.join(exp_dir,\"evaluation_results.txt\"))           \n",
    "        results = create_analysis_report(test_pred_prob, test_classes, exp_dir, LABELS_LIST)\n",
    "\n",
    "    # Plot and save losses\n",
    "    #plot_loss_acuracy(epoch_losses_history, epoch_accurcies_history,val_losses_history, \n",
    "    #                  val_accuracies_history,exp_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
